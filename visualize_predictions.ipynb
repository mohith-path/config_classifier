{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from cc.model import Classifier\n",
    "from cc.dataset import CCDataset\n",
    "\n",
    "import caml_core as core\n",
    "\n",
    "import torchcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"data/v3\"\n",
    "MODEL = \"v3-3_full_dataset_multiclass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = glob.glob(f\"lightning_logs/{MODEL}/checkpoints/*\")[0]\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "model = Classifier().eval()\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = CCDataset(path=DATASET_PATH, type=\"val\")\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=validation_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        drop_last=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     for sample in validation_dataloader:\n",
    "#         x, y = sample\n",
    "\n",
    "#         bolt_gt = y[0, 0].cpu().item()\n",
    "#         hinge_gt = y[0, 1].cpu().item()\n",
    "\n",
    "#         bolt_probs, hinge_probs = model.forward(x=x)\n",
    "\n",
    "#         if (\n",
    "#             (bolt_probs is not None  and (bolt_gt != bolt_probs.argmax(dim=-1).cpu().item())) or\n",
    "#             (hinge_probs is not None and hinge_gt != hinge_probs.argmax(dim=-1).cpu().item())\n",
    "#         ):\n",
    "#             print(f\"label: Bolt - {bolt_gt} \\t Hinge - {hinge_gt}\")\n",
    "#             print(f\"Pred: Bolt - {bolt_probs} \\t Hinge - {hinge_probs}\")\n",
    "\n",
    "#             image = x[0].detach().cpu().numpy().astype(np.uint8)\n",
    "#             image = core.geometry.Image(image=image.transpose((1, 2, 0)))\n",
    "#             h, w, _ = image.get_dimensions()\n",
    "#             image = image.resize((3 * h, 3 * w))\n",
    "            \n",
    "#             image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: Bolt - 2 \t Hinge - 0\n",
      "Pred: Bolt - tensor([[4.2041e-07, 5.3086e-05, 9.9995e-01]]) \t Hinge - tensor([[0.1971, 0.7996, 0.0033]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 17:14:11.998: Failed to load module \"canberra-gtk-module\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: Bolt - 2 \t Hinge - 1\n",
      "Pred: Bolt - tensor([[2.1109e-05, 9.6894e-01, 3.1038e-02]]) \t Hinge - tensor([[0.0097, 0.9819, 0.0084]])\n",
      "label: Bolt - 2 \t Hinge - 0\n",
      "Pred: Bolt - tensor([[1.9716e-05, 9.2582e-01, 7.4159e-02]]) \t Hinge - tensor([[9.9966e-01, 1.5036e-04, 1.8539e-04]])\n",
      "label: Bolt - 2 \t Hinge - 0\n",
      "Pred: Bolt - tensor([[2.5381e-05, 7.9020e-01, 2.0977e-01]]) \t Hinge - tensor([[9.9975e-01, 3.9685e-05, 2.0640e-04]])\n"
     ]
    }
   ],
   "source": [
    "# cam = torchcam.methods.XGradCAM(model, '_additional_conv')\n",
    "# np.set_printoptions(formatter={'float': '{:0.2f}'.format})\n",
    "\n",
    "\n",
    "# for index, sample in enumerate(validation_dataloader):\n",
    "#     x, y = sample\n",
    "\n",
    "#     bolt_gt = y[0, 0].cpu().item()\n",
    "#     hinge_gt = y[0, 1].cpu().item()\n",
    "\n",
    "#     # For CAM Visualization\n",
    "#     new_x = model.pre_processor(x)\n",
    "#     new_x.requires_grad = True\n",
    "\n",
    "#     bolt_probs, hinge_probs = model.forward(x=new_x, skip_pre_process=True)\n",
    "\n",
    "#     if (\n",
    "#             (bolt_probs is not None  and bolt_gt != bolt_probs.argmax(dim=-1).detach().cpu().item()) or\n",
    "#             (hinge_probs is not None and hinge_gt != hinge_probs.argmax(dim=-1).detach().cpu().item())\n",
    "#         ):\n",
    "\n",
    "#         print(f\"label: Bolt - {bolt_gt} \\t Hinge - {hinge_gt}\")\n",
    "#         print(f\"Pred: Bolt - {bolt_probs.detach().cpu()} \\t Hinge - {hinge_probs.detach().cpu()}\")\n",
    "\n",
    "#         image = x[0].detach().cpu().numpy().astype(np.uint8)\n",
    "#         image = core.geometry.Image(image=image.transpose((1, 2, 0)))\n",
    "\n",
    "#         h, w = image.get_dimensions()[:2]\n",
    "#         # Activation Map\n",
    "#         desired_probs = bolt_probs\n",
    "#         class_id = int(desired_probs.argmax(dim=-1).item())\n",
    "#         act_map = cam(class_idx=class_id, scores=desired_probs)\n",
    "#         act_map = act_map[0][0].detach().cpu().numpy().astype(float)\n",
    "#         act_map = core.geometry.Image(act_map).resize((h, w))\n",
    "#         act_map = np.power(act_map.image, 3)\n",
    "\n",
    "\n",
    "#         # Overlay activation map on the image\n",
    "#         overlaid_image = 0.2 * (image.image / 255.0) + 0.8 * act_map[..., None]\n",
    "#         overlaid_image = core.geometry.Image(overlaid_image).resize((448, 448))\n",
    "#         overlaid_image.show()\n",
    "#         # core.io.save_image(f\"bolt_viz/sample_{index}.png\", overlaid_image)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
